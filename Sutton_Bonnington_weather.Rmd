---
title: \myTitleMainTitle
authors:
  - name: Dr Paul J. Palmer
    department: Wolfson School of Mechanical, Electrical and Manufacturing Engineering
    affiliation: Loughborough University
    location: Leicestershire VC55
    email: p.j.palmer@lboro.ac.uk
abstract: |
  \myAbstract 
bibliography: references.bib
biblio-style: unsrt
output:
  bookdown::pdf_book:
    base_format: rticles::arxiv_article
    extra_dependencies: ["flafter"]
    includes:
      in_header: "preamble.tex"  

---

```{r setDefaults,  include=TRUE, echo=FALSE, warning=FALSE, message=FALSE, error=FALSE, results='asis'}
# Set code chunk options for all chunks
# These can be overridden at the chunk level, but setting global options 
# ensures consistency of chunk behaviour.
# To print a version of this document without code set echo = FALSE. 
#Include false will ignore the code chunk completely!
knitr::opts_chunk$set(include = TRUE, 
                      echo = TRUE, 
                      warning=FALSE, 
                      message=FALSE, 
                      error=FALSE, 
                     # fig.width = 3,
                    #  fig.height = 2,
                     # fig.width = 3,
                    out.width = '70%',
                      fig.align = "center",
                      results='asis')



```


# Introduction

\myTitleMainTitle

# Read Sutton Bonnington Data

Load the Tidyverse libraries and other helpers.
```{r }
# Load libraries
library(plyr)
library(tidyverse)
library(kableExtra)
library(gridExtra)
library(qqplotr)
library(readr)
```

Read the data. The absolute path helps to write code that is computer independent. the use of `fs` ensures operating system compatibility.
```{r }
# Read data
absolute.path <- rprojroot::find_rstudio_root_file()
path.to.my.data <- fs::path( absolute.path,
                             "data-ext",
                             "suttonboningtondata", 
                            ext = "txt")
```

The `read_table` function does a good job of reading the data into columns recognising 
```{r }
suttonboningtondata <- read_table(
                        path.to.my.data, 
                        skip = 5) # skip 5 lines of text

# Rename the columns to something useful

new.colnames <- c( "YYYY",
                   "mm",
                   "tmax.degC",
                   "tmin.degC",
                   "airfrost.days",
                   "rain.mm",
                   "sun.hours"
  
)

colnames(suttonboningtondata) <- new.colnames

# Drop row 1
suttonboningtondata <- suttonboningtondata[-1,] 

suttonboningtondata <- suttonboningtondata %>%
                        map_df( gsub,
                                pattern = "\\*",
                                replacement = "") %>%
                        map_df( gsub,
                                pattern = "---",
                                replacement = NA
                                )
  
# Date is not properly encoded so build a date from the data
suttonboningtondata$mm <-   stringr::str_pad(suttonboningtondata$mm, width = 2, pad = "0")
 
 # Create a date at the end of the month.
suttonboningtondata$dd <- 28
 suttonboningtondata$YYYYMMDD <-   with( suttonboningtondata, 
                                     paste( YYYY, mm, 
                                            dd, sep= "-"   )    )  


suttonboningtondata$datumEntity <- with(suttonboningtondata,
                                   paste("Sutton.Bonnington", YYYY, mm, sep = ":" )
                                   ) 
# manually name some values
suttonboningtondata$place <- "Sutton Bonnington"
suttonboningtondata$lattitude <- 52.833
suttonboningtondata$logitude <- 52.833
suttonboningtondata$logitude <- -1.250
suttonboningtondata$easting <- 450700
suttonboningtondata$northing <- 325900
suttonboningtondata$height.amsl.metre <- 48



suttonbonington.triple <- suttonboningtondata %>% 
                  map_df(as.character) %>% # Convert everything to character
                  pivot_longer(!datumEntity, # Use datumEntity as the key
                  names_to = "datumAttribute", # Save the name of the attribute
                  values_to = "datumValue" # Save the name of the value
                  ) %>% 
                  drop_na() # Drop all the NAs from datumValue

path.to.save<- fs::path( absolute.path
                               ,"data-ext","suttonboningtondata", ext = "rds")
saveRDS(suttonbonington.triple,path.to.save)


```


```{r}

# Prepare data-ss
# First prepare the long data
VC55.weather.sl <- suttonbonington.triple %>%
                  pivot_wider(
  id_cols = datumEntity,
  names_from = datumAttribute,
  values_from = datumValue)

# But we are interesting in plotting the data by date so

  VC55.weather.ss <- VC55.weather.sl %>% 
    select("YYYYMMDD", 
           "tmax.degC",
           "tmin.degC",
           "airfrost.days", 
           "sun.hours" ,
           "rain.mm")     %>%
            pivot_longer(!YYYYMMDD,# Use datumEntity as the key
                  names_to = "datumAttribute", # Save the name of the attribute
                  values_to = "datumValue") # Save the value of the attribute

# Set the data types
VC55.weather.ss$YYYYMMDD <-  VC55.weather.ss$YYYYMMDD %>% as.Date
VC55.weather.ss$datumValue <- VC55.weather.ss$datumValue %>% as.numeric()

 
path.to.save.ss<- fs::path( absolute.path
                               ,"data-ss","VC55.weather.ss", ext = "rds")
saveRDS(VC55.weather.ss, path.to.save.ss)

```

```{r}

# Check plot

data.to.plot <- VC55.weather.ss

data.to.plot %>% drop_na() %>%
ggplot(aes(colour = datumAttribute, x= YYYYMMDD, y =datumValue, group = datumAttribute) ) + 
 # geom_point() +
  geom_smooth( se = FALSE, method = "loess", formula = "y ~ x") +
  facet_wrap(~ datumAttribute)
 #   geom_line() + facet_wrap(~ datumAttribute)



```

The plots are in different units so plot z-scores instead.

```{r}

# An improved summary


data.to.plot <- VC55.weather.ss
 data.to.plot %>% drop_na() %>%
  group_by(datumAttribute) %>% 
  mutate( value = datumValue,
          Z.score = (datumValue -mean(datumValue))/sd(datumValue)
        ) %>%
  ggplot( aes(colour = datumAttribute, 
              x= YYYYMMDD, y =Z.score, 
              group = datumAttribute) ) + 
              geom_smooth( se = FALSE, method = "loess", formula = "y ~ x") + 
 #   geom_point(data =data.to.plot[abs(data.to.plot$Z.score) >= 1.5,]) +
              scale_colour_viridis_d() 


  

```

This looks good but very small deviations from the mean.

```{r}

# An improved summary
my.dist <- "norm"

data.to.plot <- VC55.weather.ss
 data.to.plot %>% drop_na() %>%
  group_by(datumAttribute) %>% 
  mutate( value = datumValue,
          Z.score = (datumValue -mean(datumValue))/sd(datumValue)
        ) %>%
 #  ggplot( aes(colour = datumAttribute, 
 #              x= YYYYMMDD, y =Z.score, 
 #              group = datumAttribute) ) + 
 #              geom_smooth( se = FALSE, method = "loess", formula = "y ~ x") + 
 # #   geom_point(data =data.to.plot[abs(data.to.plot$Z.score) >= 1.5,]) +
 #              scale_colour_viridis_d() 



#ggplot(distribution.data, aes(x=centrality)) + stat_qq( sample = norm)

ggplot(mapping = aes( 
                      group = datumAttribute,
                      sample = Z.score)) +
 #   stat_qq_band(distribution = my.dist) +
    stat_qq_line(distribution = my.dist) +
   stat_qq_point(distribution = my.dist) + 
  scale_colour_viridis_d() +
  ggtitle("Z-score compared to normal distribution") + facet_wrap(~ datumAttribute)
  

```



# References {-}
<div id="refs"></div>
\let\cleardoublepage\clearpage
