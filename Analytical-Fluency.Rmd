---
title: "Achieving Analytical Fluency With Complex Data"
subtitle: Refining the analytical process
titlerunning: Analytical Fluency
thanks: |
  The authors acknowledge EPSRC grant: EP/R513088/1 for funding the doctoral research on which this work is based.
authors:
- name: Paul J Palmer
  address: Department of YYY, University of XXX
  email: abc@def
- name: Michael Henshaw
  address: Department of ZZZ, University of WWW
  email: djf@wef
- name: Russell Lock
  address: Department of ZZZ, University of WWW
  email: djf@wef
keywords:
- key
- dictionary
- word
abstract: |
  Scientific analysis is formally presented as a rigid process typically
  Experiment; Analysis, Evaluation; and Conclusions.
  comprising: Review; Theory; Research question; Methodology;
  We do, however, question whether established methods for managing and
  analysing data are still appropriate for "Big Data", by which we mean
  data that is too big to be conveniently manipulated by manually
  intensive methods.
  is to justify why there is a need for new analytical techniques, given
  that the existing ones still work; the second is to show how an
  abstract perception of data impacts the analytical process.
  This presents two questions which we seek to address here: the first
  An example of the motivation for change is illustrated by the "Grammar
  of Graphics" (GoG) paradigm. GoG uses combinations of transforms to
  generate every possible graphic and tabulation from data presented in
  a suitable state allowing for a radical change in the analytic
  workflow, while still preserving the goals of scientific analysis.
  By framing this problem as one of transforming *data state*, we can
  mathematically describe general properties allowing the creation of
  re-usable code templates for data preparation. Coupled with "literate
  programming" techniques we show that this approach enables
  analytically fluent analysis of complex data.
bibliography: library.bib
biblio-style: spphys
authorrunning: P.J. Palmer, M. Henshaw, R.L. Lock
output:
  bookdown::pdf_book:
    base_format: rticles::springer_article
    includes:
      in_header: "jese.tex"
      keep_tex:  true  
---

```{r echo=FALSE}
# Set chunk visibility 
see.chunk <- FALSE
```

```{r child = "_header.Rmd"}

```

# Introduction {#sec:introduction}

A problem 

Scientific analysis is formally presented as a rigid process typically comprising: Review; Theory; Research question; Methodology; Experiment; Analysis, Evaluation; and Conclusions. This is a powerful framework that has stood the test of time which is the underlying format of countless academic publications. But just because this format is rigid, does not mean that there is no opportunity to improve the method used to achieve it.

If we look deeper, we can start to separate the actual process of scientific discovery from the way in which it is reported. The documentation of research and analysis that has already been completed, is very different to an exploration where the outcomes are as yet unknown. Nobel Prize winner @Szent-Gyorgyi1972 discussed this issue in 1972, long before the age of computers and "Big Data"[^1] introduced computational and data intensive research methods [@Szent-Gyorgyi1972]. He described the Apollonian as following a formally prescribed research path while a Dionysian explores the unknown. However, research and reporting are necessarily linked and one should be a clear and true interpretation of the other.

[^1]: By "Big Data" we mean data that is too big to be conveniently manipulated by manually intensive methods.

We argue here that this presumption the analytical process should follow the final method of presentation is a hindrance to the adoption of new analytical techniques. The term "reproducible research" has been coined to describe this linkage, without defining how it may be achieved, leading to discussion on the topic by [@Stodden2014; @Lewis2018a; @Leeper2014; @Gentleman2007; @Peng2015; @Drummond2018] and others.

Two questions arise from these discussions which we seek to address in the following sections: the first is to justify why there is a need for new analytical techniques, given that the existing ones still work? The second relates to the concepts we introduce in this work: how can changing our abstract perception of data beneficially impact the analytical process?

Both the need and benefit are illustrated by the "Grammar of Graphics" (GoG) paradigm [@Wilkinson2010]. GoG uses combinations of transforms to generate every possible graphic and tabulation from data that is presented in a suitable state. Thus, a researcher planning to use GoG will focus on saving research data in suitable state, so she can make many dynamic visualisations as work progresses, rather than waiting for the end of the data collation phase.

This contrasts with the typical approach where difficulties with data intensive analysis are often retrospectively blamed on imperfections within the data that are seen as requiring "cleaning" before analysis can begin. It is unfortunate that the popular spreadsheet encourages a manually intensive formatting of data and the use of visualisation tools that do not scale well with data size [@Mack2018; @Bishop2013; @Powell2008].

Our alternative approach is consider data as observations of the real world that are to be interpreted through analysis, rather than formatted tables meeting arbitrary technical specifications. This also expands on an idea hinted at in the GoG example above: there is no need to rigidly define data format in advance since the real world is clearly independent of the methods we choose to observe and record. If we believe that the knowledge we seek is encapsulated within a set of observations, then we can choose a viewpoint where we see data as starting in an initial *inconvenient state*. It follows that we must transform it into a *convenient state* for analysis. By constructing a working theory supported with a mathematical description, we show that the transformation of *data state* can be generalised to allow the creation of re-usable code templates. To explain how re-framing the problem of *imperfect data* in terms of *data state* can make such a difference to the way in which we approach the analytical process, we must first construct a methodology that takes into account the nature of data.

# Methodology {#sec:methodology}

The two questions we seek to answer are: "Why develop new analytical techniques, given that the existing ones still work?" and "How can changing our abstract perception of data beneficially impact the analytical process?" To achieve this goal we follow a pragmatic methodology that draws inspiration from the critical realism philosophy of [@Bhaskar2008] which gives context to data as observations arising from an unknowable real world. Our methodology is pragmatic in that we use public domain weather data as the case study for each step in our analytical approach. This data has the following characteristics:

-   Open Source;
-   Presented in an inconvenient state for analysis;
-   Multiple units of measure;
-   Extensible, in that related similar sources are available.

We do not, however, try to justify the analytical *results* from our case study, as the intent of this work is to demonstrate how *analytical fluency* can be achieved when faced with the complexities of real data. The reason for this caveat is due the topical subject of the case study and how it relates to the future of the real world. We emphasise that our analysis of past events is not a model for extrapolating future events.

In early drafts of this work, the case study was envisaged as a separate document, but this approach felt very artificial, and the benefits of fluency were unconvincing when presented in this way. We have rewritten it so in a recursive sense this article is a case study about the techniques used to write it. This presents a challenge on how best to structure this document to convey the essentials of the techniques we propose and allow the reader to critique the approach.

A further challenge is that that the final output will be a static document rendered from the dynamic components and will look no different from any other document. Since we cannot produce a dynamic document on paper, we will produce a report and a presentation from the same data using the same reusable elements. Given that the weather data is regularly updated though time, and there are many sources of such data, we aim to show that the overall effort of creating documents using analytically fluent methodologies is much less than repeating the same work with manually intensive processes.

The work is presented in the following order:

-   Data Definition:
    -   Consider the philosophical nature of data with special reference to the case study to create a data model.
-   Apply the model:
    -   The practical demonstration of data ready for analysis.
-   Template Concept:
    -   Building reusable programmatic elements for analysis.
-   Template Evaluation:
    -   A demonstration and evaluation of the template and its role in supporting analytical fluency.

Throughout this work we have based the practical analysis on the R Analytical language [@RCoreTeam2017]. In principle, the techniques presented here would work with other languages such as Python [@Gentleman2007], but their potential has not been explored. The detailed implementation can be found at the Github repository xxxxxxx. A presentation using the same code elements is also presented alongside the "paper" format. While this serves to demonstrate the re-usability of code, it was created as a container for the visualisations used prior to the creation of the supporting narrative. Simply put, it was easier to create both presentation and report.

# Case Study Data {#sec:case-study}

```{r ImageSuttonBonningtonData, fig.cap= "Source data showing the initial inconvenient state for analysis."}

knitr::include_graphics("image_Sutton_bonnington_data.png", dpi = 700 )
```

The case study uses data from the Sutton Bonnington long term weather monitoring station which is freely available online from [@UKMetrologicalOffice2022]. As Figure \@ref(fig:ImageSuttonBonningtonData) shows, it contains observations from 1959 to the present day, and is presented as a text file in an inconvenient format for analysis. The files contain a series of weather related observations in various units. To complicate matters some are annotated and some are missing.

However, if we unpick the file shown in Figure \@ref(fig:ImageSuttonBonningtonData) we can see that the UK Metrological Office statement that the file contains a "time series of monthly data" is true, but the data is not useable "as is" due to the way in which it is formatted. If we were to alter the observations it contains into a series of columns labelled: Date, Maximum temperature, Minimum temperature, etc., we would accept these as data for analysis, and possibly even present this revised format as "raw data" in a formal report with the justification that "nothing has been changed."

Our reason for emphasising these points are to lay the foundation for
introducing a terminology of "data state" to describe the changes in
data presentation that do not affect the inherent knowledge contained
within it. Looking ahead to Table 1 and our terminology it is clear that the data as supplied is what we term as Data *nascent* and that the *Nominal* data fields are equivalent to the column format proposed earlier in the previous paragraph. These interpretations are based entirely on what we believe the data represents about the real world and our analytical intent, if our research was to examine the observational impact of changes in meteorological recording equipment in the accuracy of long term records, then we would clearly need additional nominal data fields.

As the reader will see as the case study is developed, there has been a
noticeable trend in Sutton Bonnington local climate over the past 60
years which can be demonstrated by anyone who cares to examine the
public records. But a demonstration of an historical trend is does not
necessarily predict the future, which is why much scientific effort is
expended on developing predictive models.It is the goal of this work is
to demonstrate an effective approach to data driven analysis, so we
focus on the techniques used, rather than the analytical results.

The definitions associated with our approach of data state are presented
in Figure \@ref(fig:TerminologyIntroduction). The term "Nascent data" is
used in this work to distinguish it from the term "raw data", which is
frequently applied to data which has already been filtered and
transformed in some way, rather than to data which is truly in its "raw"
state. Justification for this viewpoint is found in work by
[@Bowker2013] whom collate a series of essays challenging presumptions
on the nature of raw data. These illustrate scenarios across multiple
scientific domains where "raw data" has been transformed and filtered by
processes applied prior to incorporation into a formal methodology. This
should not be seen as an attack on the *accuracy* of data used in the
scientific method, but instead is looking past the attractive simplicity
of idealised data into the underlying real world complexity, and the
need to describe *all* the processes needed to access that data.

```{r FigTheoryNascentData, fig.cap=" Data representation"}
knitr::include_graphics("standalone-states-nascent.pdf" )
```



With this introduction in mind, nascent data are conceptually
represented in data definition of
Figure \@ref(fig:FigTheoryNascentData), after @Fox1994, as the starting
point for the application of the template approach developed in this
work.

The model for recording observations of the real world is to save data
as "Datum Triples", consisting of Entity, Attribute, and Value. An
Entity uniquely identifies the thing that is being observed. An
Attribute is the property being observed, and the Value may be
numerical, logical, categorical or any other representation of the
observation. This approach is versatile as it allows for the definition
of new attributes on-the-fly since it makes no presumption about the
final data format. The philosophical foundation for this approach in
information systems was explored by [@Dobson2001]. Using this reasoning,
our observations are used to build theories that are tested against the
real world leading to a better understanding of reality. We regard data
as observations and see the widely accepted "Dirty Data" viewpoint as
just one possible theory that describes *imperfect data*. We propose
here "Data State" as an alternative approach, and empirically test it
using the case study data.

```{r TerminologyIntroduction, fig.cap="Terminology introduction." }

knitr::include_graphics("terminology-introduction.pdf" )
#terminology-introduction.pdf

```


# References
